---
title: "Angle Based Dynamic Learning Rate for Gradient Descent"
collection: publications
permalink: /files/angle_based_paper.pdf
excerpt: 'In our work, we propose a novel yet simple ap- proach to obtain an adaptive learning rate for gradient-based descent methods on classification tasks. Instead of the traditional approach of selecting adaptive learning rates via the decayed expectation of gradient-based terms, we use the angle between the current gradient and the new gradient: this new gradient is computed from the direction orthogonal to the current gradient, which further helps us in determining a better adaptive learning rate based on angle history, thereby, leading to relatively better accuracy compared to the existing state-of-the-art optimizers. On a wide variety of benchmark datasets with prominent image classification architectures such as ResNet, DenseNet, Efficient- Net, and VGG, we find that our method leads to the highest accuracy in most of the datasets. Moreover, we prove that our method is convergent.'
date: 2023-08-02
venue: 'The International Joint Conference on Neural Networks(IJCNN)'
paperurl: 'files/angle_based_paper.pdf'
citation: 'N. Mishra and P. Kumar, "Angle based dynamic learning rate for gradient descent," 2023 International Joint Conference on Neural Networks (IJCNN), Gold Coast, Australia, 2023, pp. 1-8, doi: 10.1109/IJCNN54540.2023.10191702.'
---
<!-- This paper is about the number 1. The number 2 is left for future work.

[Download paper here](http://academicpages.github.io/files/paper1.pdf)

Recommended citation: Your Name, You. (2009). "Paper Title Number 1." <i>Journal 1</i>. 1(1). -->